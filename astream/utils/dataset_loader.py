import os
import json
import asyncio
from typing import List, Dict, Any, Optional
from astream.utils.logger import logger
from astream.utils.http_client import HttpClient
from astream.config.app_settings import settings


class DatasetLoader:
    """Gestionnaire du dataset d'URLs directes."""
    
    def __init__(self, http_client: HttpClient):
        self.http_client = http_client
        # Utiliser un chemin relatif qui fonctionne sur Windows et Linux
        self.dataset_path = os.path.join("data", "dataset.json")
        self.dataset = {"anime": []}
        self._anime_dict = {}  # Cache pour recherche O(1)
        
    async def initialize(self):
        """Initialise le dataset au dÃ©marrage."""
        try:
            # 1. VÃ©rifier si dataset local existe
            if os.path.exists(self.dataset_path):
                logger.log("DATASET", f"Dataset local trouvÃ©: {self.dataset_path}")
                self.dataset = self._load_local_dataset()
            else:
                # 2. Si pas de dataset local ET dataset activÃ©
                if settings.DATASET_ENABLED:
                    logger.log("DATASET", "Aucun dataset local - TÃ©lÃ©chargement depuis GitHub")
                    await self._download_and_save_dataset()
                else:
                    logger.log("DATASET", "Dataset dÃ©sactivÃ© - Utilisation dataset vide")
                    self.dataset = {"anime": []}
            
            # 3. Construire le cache de recherche
            self._build_search_cache()
            
            # 4. DÃ©marrer mise Ã  jour en arriÃ¨re-plan si activÃ©e
            if settings.DATASET_ENABLED and settings.AUTO_UPDATE_DATASET:
                asyncio.create_task(self._periodic_update())
                
            logger.log("DATASET", f"InitialisÃ© avec {len(self.dataset.get('anime', []))} anime")
            
        except Exception as e:
            logger.log("ERROR", f"DATASET: Erreur initialisation: {e}")
            self.dataset = {"anime": []}
            self._anime_dict = {}
    
    def _load_local_dataset(self) -> Dict[str, Any]:
        """Charge le dataset depuis le fichier local."""
        try:
            with open(self.dataset_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                logger.log("DEBUG", f"DATASET: Dataset local chargÃ© - {len(data.get('anime', []))} anime")
                return data
        except Exception as e:
            logger.log("WARNING", f"DATASET: Erreur lecture dataset local: {e}")
            return {"anime": []}
    
    async def _download_and_save_dataset(self):
        """TÃ©lÃ©charge et sauvegarde le dataset depuis GitHub."""
        try:
            if not settings.DATASET_URL:
                logger.log("WARNING", "DATASET: DATASET_URL non configurÃ©e")
                return
                
            logger.log("DATASET", f"TÃ©lÃ©chargement depuis: {settings.DATASET_URL}")
            response = await self.http_client.get(settings.DATASET_URL)
            response.raise_for_status()
            
            remote_dataset = response.json()
            
            # CrÃ©er le dossier /data si nÃ©cessaire
            os.makedirs(os.path.dirname(self.dataset_path), exist_ok=True)
            
            # Sauvegarder localement
            with open(self.dataset_path, 'w', encoding='utf-8') as f:
                json.dump(remote_dataset, f, ensure_ascii=False, indent=2)
                
            self.dataset = remote_dataset
            logger.log("SUCCESS", f"Dataset tÃ©lÃ©chargÃ© et sauvÃ© - {len(self.dataset.get('anime', []))} anime")
            
        except Exception as e:
            logger.log("ERROR", f"DATASET: Erreur tÃ©lÃ©chargement: {e}")
            self.dataset = {"anime": []}
    
    def _build_search_cache(self):
        """Construit le cache de recherche pour performance O(1)."""
        self._anime_dict = {}
        
        for anime in self.dataset.get("anime", []):
            anime_slug = anime.get("slug")
            if anime_slug:
                if anime_slug not in self._anime_dict:
                    self._anime_dict[anime_slug] = {"streams": []}
                
                # Grouper les streams par saison/Ã©pisode/langue
                for stream in anime.get("streams", []):
                    season = stream.get("season")
                    episode = stream.get("episode") 
                    language = stream.get("language")
                    url = stream.get("url")
                    
                    if all([season is not None, episode is not None, language, url]):
                        self._anime_dict[anime_slug]["streams"].append({
                            "season": season,
                            "episode": episode,
                            "language": language,
                            "url": url
                        })
        
        logger.log("DEBUG", f"DATASET: Cache construit pour {len(self._anime_dict)} anime")
    
    async def get_streams(self, anime_slug: str, season: int, episode: int, language_filter: Optional[str] = None) -> List[Dict[str, Any]]:
        """RÃ©cupÃ¨re les streams depuis le dataset pour un Ã©pisode donnÃ©."""
        try:
            if not self.dataset.get("anime") or anime_slug not in self._anime_dict:
                return []
            
            anime_data = self._anime_dict[anime_slug]
            matching_streams = []
            
            for stream in anime_data["streams"]:
                if stream["season"] == season and stream["episode"] == episode:
                    # Filtrer par langue si demandÃ©
                    if language_filter and language_filter != "Tout":
                        if language_filter == "VOSTFR" and stream["language"] != "VOSTFR":
                            continue
                        elif language_filter == "VF" and stream["language"] not in ["VF", "VF1", "VF2"]:
                            continue
                    
                    # Format compatible avec le reste du code
                    matching_streams.append({
                        "url": stream["url"],
                        "language": stream["language"]
                    })
            
            if matching_streams:
                logger.log("DEBUG", f"DATASET: {len(matching_streams)} streams trouvÃ©s pour {anime_slug} S{season}E{episode}")
            
            return matching_streams
            
        except Exception as e:
            logger.log("ERROR", f"DATASET: Erreur rÃ©cupÃ©ration streams {anime_slug}: {e}")
            return []
    
    async def _periodic_update(self):
        """Mise Ã  jour pÃ©riodique du dataset."""
        while True:
            try:
                await asyncio.sleep(settings.DATASET_UPDATE_INTERVAL)
                
                if not settings.DATASET_URL:
                    continue
                    
                logger.log("DEBUG", "ğŸ”„ DATASET: VÃ©rification mise Ã  jour")
                
                # TÃ©lÃ©charger nouvelle version
                response = await self.http_client.get(settings.DATASET_URL)
                response.raise_for_status()
                remote_dataset = response.json()
                
                # Comparer avec version locale
                if remote_dataset != self.dataset:
                    logger.log("DATASET", "Nouvelle version dÃ©tectÃ©e - Mise Ã  jour")
                    
                    # Sauvegarder nouvelle version
                    with open(self.dataset_path, 'w', encoding='utf-8') as f:
                        json.dump(remote_dataset, f, ensure_ascii=False, indent=2)
                    
                    self.dataset = remote_dataset
                    self._build_search_cache()
                    
                    logger.log("SUCCESS", f"Dataset mis Ã  jour - {len(self.dataset.get('anime', []))} anime")
                else:
                    logger.log("DEBUG", "DATASET: Aucune mise Ã  jour nÃ©cessaire")
                    
            except Exception as e:
                logger.log("WARNING", f"DATASET: Erreur mise Ã  jour pÃ©riodique: {e}")
    
    def reload_dataset(self):
        """Recharge le dataset depuis le fichier local (pour les scripts)."""
        try:
            self.dataset = self._load_local_dataset()
            self._build_search_cache()
            logger.log("SUCCESS", f"Dataset rechargÃ© - {len(self.dataset.get('anime', []))} anime")
        except Exception as e:
            logger.log("ERROR", f"DATASET: Erreur rechargement: {e}")


# Instance globale
_dataset_loader: Optional[DatasetLoader] = None


def get_dataset_loader() -> Optional[DatasetLoader]:
    """RÃ©cupÃ¨re l'instance globale du dataset loader."""
    return _dataset_loader


def set_dataset_loader(loader: DatasetLoader):
    """DÃ©finit l'instance globale du dataset loader."""
    global _dataset_loader
    _dataset_loader = loader